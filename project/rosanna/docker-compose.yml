version: '3.8'
services:
  app:
    image: nvidia/cuda:12.1.0-devel-ubuntu22.04
    runtime: nvidia
    command: >
      /bin/bash -c "echo 'Starting Container' && echo 'Making Test File' && touch test.txt
      && echo '>>Installing Python Libs' && apt-get update && apt-get -y install python3.10 python3-pip openmpi-bin libopenmpi-dev
      && echo '>>Installing NVIDIA cuDNN' && pip install nvidia-cudnn-cu12==8.9.7.29
      && echo '>>Installing TensorRT-LLM' && pip3 install tensorrt_llm -U --pre --extra-index-url https://pypi.nvidia.com
      && echo '>>Checking TensorRT-LLM Installation' && python3 -c 'import tensorrt_llm'
      && echo '>>Installing Git and Git-LFS' && apt-get -y install git git-lfs
      && echo '>>Cloning TensorRT-LLM' && git clone https://github.com/NVIDIA/TensorRT-LLM.git
      && echo '*** done, you can detach from logs ***'
      && tail -f /dev/null"
    stdin_open: true
    tty: true
    entrypoint: ''
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    devices:
      - /dev/nvidiactl
      - /dev/nvidia-uvm
      - /dev/nvidia0
    volumes:
      - /usr/local/nvidia/lib:/usr/local/nvidia/lib
    ports:
      - "8888:8888"
